{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNND1mYfQiOQQ5Vkjl+ZHPU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uul9KYXcblQV"},"outputs":[],"source":["# %% Import packages\n","import datetime\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["# Define parameters\n","time_delta = datetime.timedelta(days=14)\n","start_date = datetime.date(year=2022, month=10, day=15)"],"metadata":{"id":"Gm9HiwEkbmWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% Define functions\n","\n","def format_date(date_string):\n","    months_encoded = {\"Jan\": \"01\", \"Feb\": \"02\", \"Mar\": \"03\", \"Apr\": \"04\",\n","                      \"May\": \"05\", \"Jun\": \"06\", \"Jul\": \"07\", \"Aug\": \"08\",\n","                      \"Sept\": \"09\", \"Oct\": \"10\", \"Nov\": \"11\", \"Dec\": \"12\"}\n","\n","    date_list = date_string.split(\"\\n\")\n","    year = int(date_list[1])\n","    month = int(months_encoded[date_list[0].split(\" \")[1]])\n","    day = int(date_list[0].split(\" \")[0])\n","    return str(datetime.date(year=year, month=month, day=day))\n","\n","def create_date(date_string):\n","    date_list = date_string.split(\"-\")\n","    year = int(date_list[0])\n","    month = int(date_list[1])\n","    day = int(date_list[2])\n","    return (datetime.date(year=year, month=month, day=day))\n","\n","def calculate_lag(trade, publish):\n","    trade_date = create_date(trade)\n","    publish_date = create_date(publish)\n","    lag = publish_date - trade_date\n","    return lag.days"],"metadata":{"id":"JKw6DgeebpvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% Load data\n","\n","imported_data = pd.read_csv(\"capitoltrades.csv\")\n","\n","processed_data = {}\n","processed_data[\"Politician\"] = []\n","processed_data[\"Chamber\"] = []\n","processed_data[\"Party\"] = []\n","processed_data[\"State\"] = []\n","processed_data[\"Owner\"] = []\n","processed_data[\"Traded\"] = []\n","processed_data[\"Published\"] = []\n","processed_data[\"Ticker\"] = []\n","processed_data[\"Size\"] = []\n","processed_data[\"Price\"] = []\n","\n","\n","for row in imported_data.iterrows():\n","    if \":US\" in row[1][\"Traded Issuer\"]:\n","        # Append the politician data\n","        politician_data = row[1][\"Politician\"].split(\"\\n\")\n","        processed_data[\"Politician\"].append(politician_data[0])\n","        if \"House\" in politician_data[1]: processed_data[\"Chamber\"].append(\"House\")\n","        else: processed_data[\"Chamber\"].append(\"Senate\")\n","        if \"Democrat\" in politician_data[1]: processed_data[\"Party\"].append(\"Democrat\")\n","        else: processed_data[\"Party\"].append(\"Republican\")\n","        processed_data[\"State\"].append(politician_data[1][-2:])\n","        processed_data[\"Owner\"].append(row[1][\"Owner\"])\n","\n","        # Append the date data\n","        processed_data[\"Traded\"].append(format_date(row[1][\"Traded\"]))\n","        processed_data[\"Published\"].append(format_date(row[1][\"Published\"]))\n","\n","        # Apend the trade information\n","        processed_data[\"Ticker\"].append(row[1][\"Traded Issuer\"].split(\"\\n\")[1].replace(\":US\", \"\"))\n","        processed_data[\"Size\"].append(row[1][\"Size\"])\n","        if str(row[1][\"Price\"]) == 'nan': processed_data[\"Price\"].append('nan')\n","        else: processed_data[\"Price\"].append(row[1][\"Price\"].replace(\"$\", \"\"))\n","\n","processed_data_DF = pd.DataFrame(processed_data)"],"metadata":{"id":"HDnfB8K4brmC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% Save when sorting by trade date\n","\n","processed_data_DF_sorted = processed_data_DF.sort_values(by=\"Traded\")\n","processed_data_DF_sorted.to_csv(\"congress_by_trade_date.csv\", index=False)\n","\n","start_temp = start_date\n","end_temp = start_date + time_delta\n","end_date = create_date(max([max(processed_data_DF_sorted[\"Traded\"]), max(processed_data_DF_sorted[\"Published\"])]))\n","\n","biweekly_data = {}\n","biweekly_data[\"start_date\"] = []\n","biweekly_data[\"end_date\"] = []\n","biweekly_data[\"ticker\"] = []\n","biweekly_data[\"lag\"] = []\n","biweekly_data[\"n_trades\"] = []\n","biweekly_data[\"Democrat\"] = []\n","biweekly_data[\"Senate\"] = []\n","biweekly_data[\"Size\"] = []\n","\n","\n","while end_temp < end_date:\n","\n","    temp1 = processed_data_DF_sorted[processed_data_DF_sorted[\"Traded\"] > str(start_temp)]\n","    temp2 = temp1[temp1[\"Traded\"] < str(end_temp)]\n","\n","    for tick in np.unique(temp2[\"Ticker\"]):\n","        ticker_temp = temp2[temp2[\"Ticker\"] == tick]\n","\n","        biweekly_data[\"start_date\"].append(str(start_temp))\n","        biweekly_data[\"end_date\"].append(str(end_temp))\n","        biweekly_data[\"ticker\"].append(tick)\n","\n","        all_lags = []\n","        for entry in ticker_temp.iterrows():\n","            all_lags.append(calculate_lag(entry[1][\"Traded\"], entry[1][\"Published\"]))\n","        biweekly_data[\"lag\"].append(sum(all_lags) / len(all_lags))\n","        biweekly_data[\"n_trades\"].append(len(ticker_temp))\n","\n","        biweekly_data[\"Democrat\"].append(len(ticker_temp[ticker_temp[\"Party\"]==\"Democrat\"]) / len(ticker_temp))\n","        biweekly_data[\"Senate\"].append(len(ticker_temp[ticker_temp[\"Chamber\"]==\"Senate\"]) / len(ticker_temp))\n","        biweekly_data[\"Size\"].append()\n","\n","\n","    start_temp = end_temp\n","    end_temp = start_temp + time_delta\n","\n","\n","pd.DataFrame(biweekly_data).to_csv(\"congress_by_trade_date.biweekly.csv\", index=False)"],"metadata":{"id":"zyXd-ipRbuDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% Save when sorting by declaration date\n","\n","processed_data_DF_sorted = processed_data_DF.sort_values(by=\"Published\")\n","processed_data_DF_sorted.to_csv(\"congress_by_declared_date.csv\", index=False)\n","\n","start_temp = start_date\n","end_temp = start_date + time_delta\n","end_date = create_date(max([max(processed_data_DF_sorted[\"Traded\"]), max(processed_data_DF_sorted[\"Published\"])]))\n","\n","biweekly_data = {}\n","biweekly_data[\"start_date\"] = []\n","biweekly_data[\"end_date\"] = []\n","biweekly_data[\"ticker\"] = []\n","biweekly_data[\"lag\"] = []\n","biweekly_data[\"n_trades\"] = []\n","biweekly_data[\"Democrat\"] = []\n","biweekly_data[\"Senate\"] = []\n","\n","while end_temp < end_date:\n","\n","    temp1 = processed_data_DF_sorted[processed_data_DF_sorted[\"Published\"] > str(start_temp)]\n","    temp2 = temp1[temp1[\"Published\"] < str(end_temp)]\n","\n","    for tick in np.unique(temp2[\"Ticker\"]):\n","        ticker_temp = temp2[temp2[\"Ticker\"] == tick]\n","\n","        biweekly_data[\"start_date\"].append(str(start_temp))\n","        biweekly_data[\"end_date\"].append(str(end_temp))\n","        biweekly_data[\"ticker\"].append(tick)\n","\n","        all_lags = []\n","        for entry in ticker_temp.iterrows():\n","            all_lags.append(calculate_lag(entry[1][\"Traded\"], entry[1][\"Published\"]))\n","        biweekly_data[\"lag\"].append(sum(all_lags) / len(all_lags))\n","        biweekly_data[\"n_trades\"].append(len(ticker_temp))\n","\n","        biweekly_data[\"Democrat\"].append(len(ticker_temp[ticker_temp[\"Party\"]==\"Democrat\"]) / len(ticker_temp))\n","        biweekly_data[\"Senate\"].append(len(ticker_temp[ticker_temp[\"Chamber\"]==\"Senate\"]) / len(ticker_temp))\n","\n","    start_temp = end_temp\n","    end_temp = start_temp + time_delta\n","\n","\n","pd.DataFrame(biweekly_data).to_csv(\"congress_by_declared_date.biweekly.csv\", index=False)"],"metadata":{"id":"m6prygxgbwxR"},"execution_count":null,"outputs":[]}]}